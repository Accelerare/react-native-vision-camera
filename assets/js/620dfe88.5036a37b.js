(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{124:function(e,t,a){"use strict";a.d(t,"a",(function(){return b})),a.d(t,"b",(function(){return m}));var n=a(0),r=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function c(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=r.a.createContext({}),l=function(e){var t=r.a.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):c(c({},t),e)),a},b=function(e){var t=l(e.components);return r.a.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},u=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,o=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),b=l(a),u=n,m=b["".concat(o,".").concat(u)]||b[u]||d[u]||i;return a?r.a.createElement(m,c(c({ref:t},p),{},{components:a})):r.a.createElement(m,c({ref:t},p))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,o=new Array(i);o[0]=u;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:n,o[1]=c;for(var p=2;p<i;p++)o[p]=a[p];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,a)}u.displayName="MDXCreateElement"},125:function(e,t,a){"use strict";a.d(t,"b",(function(){return i})),a.d(t,"a",(function(){return o}));var n=a(16),r=a(127);function i(){var e=Object(n.default)().siteConfig,t=(e=void 0===e?{}:e).baseUrl,a=void 0===t?"/":t,i=e.url;return{withBaseUrl:function(e,t){return function(e,t,a,n){var i=void 0===n?{}:n,o=i.forcePrependBaseUrl,c=void 0!==o&&o,s=i.absolute,p=void 0!==s&&s;if(!a)return a;if(a.startsWith("#"))return a;if(Object(r.b)(a))return a;if(c)return t+a;var l=a.startsWith(t)?a:t+a.replace(/^\//,"");return p?e+l:l}(i,a,e,t)}}}function o(e,t){return void 0===t&&(t={}),(0,i().withBaseUrl)(e,t)}},127:function(e,t,a){"use strict";function n(e){return!0===/^(\w*:|\/\/)/.test(e)}function r(e){return void 0!==e&&!n(e)}a.d(t,"b",(function(){return n})),a.d(t,"a",(function(){return r}))},92:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return c})),a.d(t,"metadata",(function(){return s})),a.d(t,"toc",(function(){return p})),a.d(t,"default",(function(){return b}));var n=a(3),r=a(7),i=(a(0),a(124)),o=a(125),c={id:"capturing",title:"Taking Photos/Recording Videos",sidebar_label:"Taking Photos/Recording Videos"},s={unversionedId:"guides/capturing",id:"guides/capturing",isDocsHomePage:!1,title:"Taking Photos/Recording Videos",description:"Camera Actions",source:"@site/docs/guides/CAPTURING.mdx",slug:"/guides/capturing",permalink:"/react-native-vision-camera/docs/guides/capturing",editUrl:"https://github.com/cuvent/react-native-vision-camera/edit/main/docs/docs/guides/CAPTURING.mdx",version:"current",sidebar_label:"Taking Photos/Recording Videos",sidebar:"visionSidebar",previous:{title:"Camera Formats",permalink:"/react-native-vision-camera/docs/guides/formats"},next:{title:"Frame Processors",permalink:"/react-native-vision-camera/docs/guides/frame-processors"}},p=[{value:"Camera Actions",id:"camera-actions",children:[]},{value:"Taking Photos",id:"taking-photos",children:[{value:"Taking Snapshots",id:"taking-snapshots",children:[]}]},{value:"Recording Videos",id:"recording-videos",children:[]},{value:"Focussing",id:"focussing",children:[]}],l={toc:p};function b(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(n.a)({},l,a,{components:t,mdxType:"MDXLayout"}),Object(i.b)("div",null,Object(i.b)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"283",height:"535",style:{float:"right"}},Object(i.b)("image",{href:Object(o.a)("img/demo_capture.gif"),x:"18",y:"33",width:"247",height:"469"}),Object(i.b)("image",{href:Object(o.a)("img/frame.png"),width:"283",height:"535"}))),Object(i.b)("h2",{id:"camera-actions"},"Camera Actions"),Object(i.b)("p",null,"The Camera provides certain actions using member functions which are available by using a ",Object(i.b)("a",{parentName:"p",href:"https://reactjs.org/docs/refs-and-the-dom.html"},"ref object"),":"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-tsx"},"function App() {\n  const camera = useRef<Camera>(null)\n  // ...\n\n  return (\n    <Camera\n      ref={camera}\n      {...cameraProps}\n    />\n  )\n}\n")),Object(i.b)("p",null,"The most important actions are:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#taking-photos"},"Taking Photos"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#taking-snapshots"},"Taking Snapshots")))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#recording-videos"},"Recording Videos")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"#focussing"},"Focussing"))),Object(i.b)("h2",{id:"taking-photos"},"Taking Photos"),Object(i.b)("p",null,"To take a photo, simply use the Camera's ",Object(i.b)("a",{parentName:"p",href:"../api/classes/camera.camera-1#takephoto"},Object(i.b)("inlineCode",{parentName:"a"},"takePhoto(...)"))," function:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-ts"},"const photo = await camera.current.takePhoto({\n  flash: 'on'\n})\n")),Object(i.b)("p",null,"You can customize capture options such as ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions#enableautoredeyereduction"},"automatic red-eye reduction"),", ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions#enableautostabilization"},"automatic image stabilization"),", ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions#enablevirtualdevicefusion"},"combining images from constituent physical camera devices")," to create a single high quality fused image, ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions#flash"},"enable flash"),", ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions#qualityprioritization"},"prioritize speed over quality")," and more using the ",Object(i.b)("inlineCode",{parentName:"p"},"options")," parameter. (See ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.takephotooptions"},Object(i.b)("inlineCode",{parentName:"a"},"TakePhotoOptions")),")"),Object(i.b)("p",null,"This function returns a ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.photofile-1"},Object(i.b)("inlineCode",{parentName:"a"},"PhotoFile"))," which contains a ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/photofile.photofile-1#path"},Object(i.b)("inlineCode",{parentName:"a"},"path"))," property you can display in your App using an ",Object(i.b)("inlineCode",{parentName:"p"},"<Image>")," or ",Object(i.b)("inlineCode",{parentName:"p"},"<FastImage>"),"."),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"},"This will change with the upcoming React Native Re-Architecture, so that instead of writing a temporary file which you have to read again, this function will immediately return an Image HostObject on which you can directly interop with the underlying ",Object(i.b)("inlineCode",{parentName:"p"},"UIImage"),"/",Object(i.b)("inlineCode",{parentName:"p"},"Bitmap")," for faster image capture. See ",Object(i.b)("a",{parentName:"p",href:"https://github.com/cuvent/react-native-vision-camera/issues/69"},"issue #69")))),Object(i.b)("h3",{id:"taking-snapshots"},"Taking Snapshots"),Object(i.b)("p",null,"Compared to iOS, Cameras on Android tend to be slower in image capture. If you care about speed, you can use the Camera's ",Object(i.b)("a",{parentName:"p",href:"../api/classes/camera.camera-1#takesnapshot"},Object(i.b)("inlineCode",{parentName:"a"},"takeSnapshot(...)"))," function (Android only) which simply takes a snapshot of the Camera View instead of actually taking a photo through the Camera lens."),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-ts"},"const snapshot = await camera.current.takeSnapshot({\n  quality: 85,\n  skipMetadata: true\n})\n")),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"},"While taking Snapshots is faster than taking Photos, the resulting image has way lower quality. You can combine both functions to create a Snapshot for presenting to the User at first, then deliver the actual Photo afterwards."))),Object(i.b)("h2",{id:"recording-videos"},"Recording Videos"),Object(i.b)("p",null,"To start a video recording, use the Camera's ",Object(i.b)("a",{parentName:"p",href:"../api/classes/camera.camera-1#startrecording"},Object(i.b)("inlineCode",{parentName:"a"},"startRecording(...)"))," function:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-ts"},"camera.current.startRecording({\n  flash: 'on',\n  onRecordingFinished: (video) => console.log(video),\n  onRecordingError: (error) => console.error(error),\n})\n")),Object(i.b)("p",null,"For any error that occured ",Object(i.b)("em",{parentName:"p"},"while recording the video"),", the ",Object(i.b)("inlineCode",{parentName:"p"},"onRecordingError")," callback will be invoked with a ",Object(i.b)("a",{parentName:"p",href:"../api/classes/cameraerror.cameracaptureerror"},Object(i.b)("inlineCode",{parentName:"a"},"CaptureError"))," and the recording is therefore cancelled."),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"},"Due to limitations of the React Native Bridge, this function can not be awaited. This means, any errors thrown while trying to start the recording (e.g. ",Object(i.b)("inlineCode",{parentName:"p"},"capture/recording-in-progress"),") can only be caught synchronously (",Object(i.b)("inlineCode",{parentName:"p"},"isBlockingSynchronousMethod"),"). This will change with the upcoming React Native Re-Architecture."))),Object(i.b)("p",null,"To stop the video recording, you can call ",Object(i.b)("a",{parentName:"p",href:"../api/classes/camera.camera-1#stoprecording"},Object(i.b)("inlineCode",{parentName:"a"},"stopRecording(...)")),":"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-ts"},"await camera.current.stopRecording()\n")),Object(i.b)("p",null,"Once a recording has been stopped, the ",Object(i.b)("inlineCode",{parentName:"p"},"onRecordingFinished")," callback passed to the ",Object(i.b)("inlineCode",{parentName:"p"},"startRecording")," function will be invoked with a ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/videofile.videofile-1"},Object(i.b)("inlineCode",{parentName:"a"},"VideoFile"))," which you can then use to display in a ",Object(i.b)("a",{parentName:"p",href:"https://github.com/react-native-video/react-native-video"},Object(i.b)("inlineCode",{parentName:"a"},"<Video>"))," component."),Object(i.b)("h2",{id:"focussing"},"Focussing"),Object(i.b)("p",null,"To focus the camera to a specific point, simply use the Camera's ",Object(i.b)("a",{parentName:"p",href:"../api/classes/camera.camera-1#focus"},Object(i.b)("inlineCode",{parentName:"a"},"focus(...)"))," function:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-ts"},"await camera.current.focus({ x: tapEvent.x, y: tapEvent.y })\n")),Object(i.b)("p",null,"The focus function expects a ",Object(i.b)("a",{parentName:"p",href:"../api/interfaces/point.point-1"},Object(i.b)("inlineCode",{parentName:"a"},"Point"))," parameter which represents the location relative to the Camera View where you want to focus the Camera to. If you use react-native-gesture-handler, this will consist of the ",Object(i.b)("a",{parentName:"p",href:"https://docs.swmansion.com/react-native-gesture-handler/docs/api/gesture-handlers/tap-gh#x"},Object(i.b)("inlineCode",{parentName:"a"},"x"))," and ",Object(i.b)("a",{parentName:"p",href:"https://docs.swmansion.com/react-native-gesture-handler/docs/api/gesture-handlers/tap-gh#y"},Object(i.b)("inlineCode",{parentName:"a"},"y"))," properties of the tap event payload."),Object(i.b)("p",null,"So for example, ",Object(i.b)("inlineCode",{parentName:"p"},"{ x: 0, y: 0 }")," will focus to the upper left corner, while ",Object(i.b)("inlineCode",{parentName:"p"},"{ x: CAM_WIDTH, y: CAM_HEIGHT }")," will focus to the bottom right corner."),Object(i.b)("p",null,"Focussing adjusts auto-focus (AF) and auto-exposure (AE)."),Object(i.b)("br",null),Object(i.b)("h4",{id:"-next-section-frame-processors"},"\ud83d\ude80 Next section: ",Object(i.b)("a",{parentName:"h4",href:"frame-processors"},"Frame Processors")))}b.isMDXComponent=!0}}]);