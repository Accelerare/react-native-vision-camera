(self.webpackChunkvision_camera=self.webpackChunkvision_camera||[]).push([[8191],{3905:function(e,r,t){"use strict";t.d(r,{Zo:function(){return u},kt:function(){return d}});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function o(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?o(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function i(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=n.createContext({}),c=function(e){var r=n.useContext(l),t=r;return e&&(t="function"==typeof e?e(r):s(s({},r),e)),t},u=function(e){var r=c(e.components);return n.createElement(l.Provider,{value:r},e.children)},p={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},m=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),m=c(t),d=a,f=m["".concat(l,".").concat(d)]||m[d]||p[d]||o;return t?n.createElement(f,s(s({ref:r},u),{},{components:t})):n.createElement(f,s({ref:r},u))}));function d(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var o=t.length,s=new Array(o);s[0]=m;var i={};for(var l in r)hasOwnProperty.call(r,l)&&(i[l]=r[l]);i.originalType=e,i.mdxType="string"==typeof e?e:a,s[1]=i;for(var c=2;c<o;c++)s[c]=t[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}m.displayName="MDXCreateElement"},3919:function(e,r,t){"use strict";function n(e){return!0===/^(\w*:|\/\/)/.test(e)}function a(e){return void 0!==e&&!n(e)}t.d(r,{b:function(){return n},Z:function(){return a}})},4996:function(e,r,t){"use strict";t.d(r,{C:function(){return o},Z:function(){return s}});var n=t(2263),a=t(3919);function o(){var e=(0,n.default)().siteConfig,r=(e=void 0===e?{}:e).baseUrl,t=void 0===r?"/":r,o=e.url;return{withBaseUrl:function(e,r){return function(e,r,t,n){var o=void 0===n?{}:n,s=o.forcePrependBaseUrl,i=void 0!==s&&s,l=o.absolute,c=void 0!==l&&l;if(!t)return t;if(t.startsWith("#"))return t;if((0,a.b)(t))return t;if(i)return r+t;var u=t.startsWith(r)?t:r+t.replace(/^\//,"");return c?e+u:u}(o,t,e,r)}}}function s(e,r){return void 0===r&&(r={}),(0,o().withBaseUrl)(e,r)}},5226:function(e,r,t){"use strict";t.r(r),t.d(r,{frontMatter:function(){return i},metadata:function(){return l},toc:function(){return c},default:function(){return p}});var n=t(2122),a=t(9756),o=(t(7294),t(3905)),s=t(4996),i={id:"frame-processors-plugins-overview",title:"Creating Frame Processor Plugins",sidebar_label:"Overview"},l={unversionedId:"guides/frame-processors-plugins-overview",id:"guides/frame-processors-plugins-overview",isDocsHomePage:!1,title:"Creating Frame Processor Plugins",description:"Overview",source:"@site/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx",sourceDirName:"guides",slug:"/guides/frame-processors-plugins-overview",permalink:"/react-native-vision-camera/docs/guides/frame-processors-plugins-overview",editUrl:"https://github.com/cuvent/react-native-vision-camera/edit/main/docs/docs/guides/FRAME_PROCESSORS_CREATE_OVERVIEW.mdx",version:"current",sidebar_label:"Overview",frontMatter:{id:"frame-processors-plugins-overview",title:"Creating Frame Processor Plugins",sidebar_label:"Overview"},sidebar:"visionSidebar",previous:{title:"Frame Processors",permalink:"/react-native-vision-camera/docs/guides/frame-processors"},next:{title:"Creating Frame Processor Plugins for iOS",permalink:"/react-native-vision-camera/docs/guides/frame-processors-plugins-ios"}},c=[{value:"Overview",id:"overview",children:[{value:"Execution",id:"execution",children:[]},{value:"Return Types",id:"return-types",children:[]},{value:"Parameters",id:"parameters",children:[]},{value:"Long-running Frame Processors",id:"long-running-frame-processors",children:[]},{value:"Async Frame Processors with Event Emitters",id:"async-frame-processors-with-event-emitters",children:[]},{value:"Benchmarking Frame Processor Plugins",id:"benchmarking-frame-processor-plugins",children:[]}]}],u={toc:c};function p(e){var r=e.components,t=(0,a.Z)(e,["components"]);return(0,o.kt)("wrapper",(0,n.Z)({},u,t,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"overview"},"Overview"),(0,o.kt)("p",null,"Frame Processor Plugins are ",(0,o.kt)("strong",{parentName:"p"},"native functions")," which can be directly called from a JS Frame Processor. (See ",(0,o.kt)("a",{parentName:"p",href:"frame-processors"},"Frame Processors"),")"),(0,o.kt)("p",null,"They ",(0,o.kt)("strong",{parentName:"p"},"receive a frame from the Camera")," as an input and can return any kind of output. For example, a ",(0,o.kt)("inlineCode",{parentName:"p"},"scanQRCodes")," function returns an array of detected QR code strings in the frame:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx",metastring:"{4-5}","{4-5}":!0},"function App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    const qrCodes = scanQRCodes(frame)\n    _log(`QR Codes in Frame: ${qrCodes}`)\n  }, [])\n\n  return (\n    <Camera frameProcessor={frameProcessor} {...cameraProps} />\n  )\n}\n")),(0,o.kt)("p",null,"To achieve ",(0,o.kt)("strong",{parentName:"p"},"maximum performance"),", the ",(0,o.kt)("inlineCode",{parentName:"p"},"scanQRCodes")," function is written in a native language (e.g. Objective-C), but it will be directly called from the VisionCamera Frame Processor JavaScript-Runtime."),(0,o.kt)("h3",{id:"execution"},"Execution"),(0,o.kt)("p",null,"Frame Processors will be ",(0,o.kt)("strong",{parentName:"p"},"synchronously")," called for each frame the Camera sees and have to finish executing before the next frame arrives, otherwise the next frame(s) will be dropped. For a frame rate of ",(0,o.kt)("strong",{parentName:"p"},"30 FPS"),", you have about ",(0,o.kt)("strong",{parentName:"p"},"33ms")," to finish processing frames. Use ",(0,o.kt)("a",{parentName:"p",href:"../api/interfaces/cameraprops.cameraprops-1#frameprocessorfps"},(0,o.kt)("inlineCode",{parentName:"a"},"frameProcessorFps"))," to throttle the frame processor's FPS. For a QR Code Scanner, ",(0,o.kt)("strong",{parentName:"p"},"5 FPS")," might suffice."),(0,o.kt)("h3",{id:"return-types"},"Return Types"),(0,o.kt)("p",null,"Frame Processors can return any primitive value that is representable in JS. So for Objective-C that maps to:"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Objective-C Type"),(0,o.kt)("th",{parentName:"tr",align:null},"JS Type"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"NSNumber")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"number"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"NSNumber")," (boolean)"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"boolean"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"NSString")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"string"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"NSArray")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"[]"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"NSDictionary")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"{}"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"nil")," / ",(0,o.kt)("inlineCode",{parentName:"td"},"NSNull")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"undefined"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"RCTResponseSenderBlock")),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"(any, any) => void"))))),(0,o.kt)("p",null,"The values will automatically be converted to JS values, so the following Objective-C frame processor:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-objc"},'static inline id detectObject(CMSampleBufferRef buffer, NSArray args) {\n  return @"cat";\n}\n')),(0,o.kt)("p",null,"Returns a ",(0,o.kt)("inlineCode",{parentName:"p"},"string")," in JS:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"export function detectObject(frame: Frame): string {\n  'worklet';\n  const result =  __detectObject(frame);\n  _log(result) // <-- \"cat\"\n}\n")),(0,o.kt)("h3",{id:"parameters"},"Parameters"),(0,o.kt)("p",null,"Frame Processors can also accept parameters, following the same type convention as ",(0,o.kt)("a",{parentName:"p",href:"#return-types"},"return values"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-ts"},"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const codes = scanCodes(frame, ['qr', 'barcode'])\n}, [])\n")),(0,o.kt)("p",null,"Or with multiple parameters:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-ts"},"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet'\n  const codes = scanCodes(frame, true, 'hello-world', 42)\n}, [])\n")),(0,o.kt)("h3",{id:"long-running-frame-processors"},"Long-running Frame Processors"),(0,o.kt)("p",null,"If your Frame Processor takes longer than a single frame interval to execute, or runs asynchronously, you can create a ",(0,o.kt)("strong",{parentName:"p"},"copy of the frame")," and dispatch the actual frame processing to a ",(0,o.kt)("strong",{parentName:"p"},"separate thread"),"."),(0,o.kt)("p",null,"For example, a realtime video chat application might use WebRTC to send the frames to the server. I/O operations (networking) are asynchronous, and we don't ",(0,o.kt)("em",{parentName:"p"},"need")," to wait for the upload to succeed before pushing the next frame, so we copy the frame and perform the upload on another Thread."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-objc"},"static dispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0ul);\n\nstatic inline id sendFrameToWebRTC(CMSampleBufferRef buffer, NSArray args) {\n  CMSampleBufferRef bufferCopy;\n  CMSampleBufferCreateCopy(kCFAllocatorDefault, &buffer, &bufferCopy);\n\n  dispatch_async(queue, ^{\n    NSString* serverURL = (NSString*)args[0];\n    [WebRTC uploadFrame:bufferCopy toServer:serverURL];\n  });\n\n  return nil;\n}\n")),(0,o.kt)("h3",{id:"async-frame-processors-with-event-emitters"},"Async Frame Processors with Event Emitters"),(0,o.kt)("p",null,"You might also run some very complex AI algorithms which are not fast enough to smoothly run at ",(0,o.kt)("strong",{parentName:"p"},"30 FPS")," (",(0,o.kt)("strong",{parentName:"p"},"33ms"),'). To not drop any frames you can create a custom "frame queue" which processes the copied frames and calls back into JS via a React event emitter. For this you\'ll have to create a Native Module that handles the asynchronous native -> JS communication, see ',(0,o.kt)("a",{parentName:"p",href:"https://reactnative.dev/docs/native-modules-android#sending-events-to-javascript"},'"Sending events to JavaScript" (Android)')," and ",(0,o.kt)("a",{parentName:"p",href:"https://reactnative.dev/docs/native-modules-ios#sending-events-to-javascript"},'"Sending events to JavaScript" (iOS)'),"."),(0,o.kt)("p",null,"This might look like this for the user:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-tsx"},"function App() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet'\n    SomeAI.process(frame) // does not block frame processor, runs async\n  }, [])\n\n  useEffect(() => {\n    SomeAI.addListener((results) => {\n      console.log(`AI results: ${results}`)\n    })\n  }, [])\n\n  return (\n    <Camera frameProcessor={frameProcessor} {...cameraProps} />\n  )\n}\n")),(0,o.kt)("p",null,"This way you can handle queueing up the frames yourself and asynchronously call back into JS at some later point in time using event emitters."),(0,o.kt)("h3",{id:"benchmarking-frame-processor-plugins"},"Benchmarking Frame Processor Plugins"),(0,o.kt)("p",null,"Your Frame Processor Plugins have to be fast. VisionCamera automatically detects slow Frame Processors and outputs relevant information in the native console (Xcode: ",(0,o.kt)("strong",{parentName:"p"},"Debug Area"),", Android Studio: ",(0,o.kt)("strong",{parentName:"p"},"Logcat"),"):"),(0,o.kt)("div",{align:"center"},(0,o.kt)("img",{src:(0,s.Z)("img/slow-log.png"),width:"80%"})),(0,o.kt)("div",{align:"center"},(0,o.kt)("img",{src:(0,s.Z)("img/slow-log-2.png"),width:"80%"})),(0,o.kt)("br",null),(0,o.kt)("h4",{id:"-create-your-first-frame-processor-plugin-for-ios-or-android"},"\ud83d\ude80 Create your first Frame Processor Plugin for ",(0,o.kt)("a",{parentName:"h4",href:"frame-processors-plugins-ios"},"iOS")," or ",(0,o.kt)("a",{parentName:"h4",href:"frame-processors-plugins-android"},"Android"),"!"))}p.isMDXComponent=!0}}]);